{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 - Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Load dataset](#Load-dataset)\n",
    "- [The Default data set](#Figure-4.1---Default-data-set)\n",
    "- [4.3 Logistic Regression](#4.3-Logistic-Regression)\n",
    "- [4.4 Linear Discriminant Analysis](#4.4-Linear-Discriminant-Analysis)\n",
    "- [Lab: 4.6.3 Linear Discriminant Analysis](#4.6.3-Linear-Discriminant-Analysis)\n",
    "- [Lab: 4.6.4 Quadratic Discriminant Analysis](#4.6.4-Quadratic-Discriminant-Analysis)\n",
    "- [Lab: 4.6.5 K-Nearest Neighbors](#4.6.5-K-Nearest-Neighbors)\n",
    "- [Lab: 4.6.6 An Application to Caravan Insurance Data](#4.6.6-An-Application-to-Caravan-Insurance-Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../standard_import.txt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn.linear_model as skl_lm\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import neighbors\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-white')\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In R, I exported the dataset from package 'ISLR' to an Excel file\n",
    "df = pd.read_excel('Data/Default.xlsx')\n",
    "\n",
    "# Note: factorize() returns two objects: a label array and an array with the unique values.\n",
    "# We are only interested in the first object. \n",
    "df['default2'] = df.default.factorize()[0]\n",
    "df['student2'] = df.student.factorize()[0]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Figure 4.1 - Default data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,5))\n",
    "gs = mpl.gridspec.GridSpec(1, 4)\n",
    "ax1 = plt.subplot(gs[0,:-2])\n",
    "ax2 = plt.subplot(gs[0,-2])\n",
    "ax3 = plt.subplot(gs[0,-1])\n",
    "\n",
    "# Take a fraction of the samples where target value (default) is 'no'\n",
    "df_no = df[df.default2 == 0].sample(frac=0.15)\n",
    "# Take all samples  where target value is 'yes'\n",
    "df_yes = df[df.default2 == 1]\n",
    "df_ = df_no.append(df_yes)\n",
    "\n",
    "ax1.scatter(df_[df_.default == 'Yes'].balance, df_[df_.default == 'Yes'].income, s=40, c='orange', marker='+',\n",
    "            linewidths=1)\n",
    "ax1.scatter(df_[df_.default == 'No'].balance, df_[df_.default == 'No'].income, s=40, marker='o', linewidths='1',\n",
    "            edgecolors='lightblue', facecolors='white', alpha=.6)\n",
    "\n",
    "ax1.set_ylim(ymin=0)\n",
    "ax1.set_ylabel('Income')\n",
    "ax1.set_xlim(xmin=-100)\n",
    "ax1.set_xlabel('Balance')\n",
    "\n",
    "c_palette = {'No':'lightblue', 'Yes':'orange'}\n",
    "sns.boxplot('default', 'balance', data=df, orient='v', ax=ax2, palette=c_palette)\n",
    "sns.boxplot('default', 'income', data=df, orient='v', ax=ax3, palette=c_palette)\n",
    "gs.tight_layout(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Logistic Regression\n",
    "### Figure 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.balance.values.reshape(-1,1) \n",
    "y = df.default2\n",
    "\n",
    "# Create array of test data. Calculate the classification probability\n",
    "# and predicted classification.\n",
    "X_test = np.arange(df.balance.min(), df.balance.max()).reshape(-1,1)\n",
    "\n",
    "clf = skl_lm.LogisticRegression(solver='newton-cg')\n",
    "clf.fit(X_train,y)\n",
    "prob = clf.predict_proba(X_test)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,5))\n",
    "# Left plot\n",
    "sns.regplot(df.balance, df.default2, order=1, ci=None,\n",
    "            scatter_kws={'color':'orange'},\n",
    "            line_kws={'color':'lightblue', 'lw':2}, ax=ax1)\n",
    "# Right plot\n",
    "ax2.scatter(X_train, y, color='orange')\n",
    "ax2.plot(X_test, prob[:,1], color='lightblue')\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.hlines(1, xmin=ax.xaxis.get_data_interval()[0],\n",
    "              xmax=ax.xaxis.get_data_interval()[1], linestyles='dashed', lw=1)\n",
    "    ax.hlines(0, xmin=ax.xaxis.get_data_interval()[0],\n",
    "              xmax=ax.xaxis.get_data_interval()[1], linestyles='dashed', lw=1)\n",
    "    ax.set_ylabel('Probability of default')\n",
    "    ax.set_xlabel('Balance')\n",
    "    ax.set_yticks([0, 0.25, 0.5, 0.75, 1.])\n",
    "    ax.set_xlim(xmin=-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.default2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using newton-cg solver, the coefficients are equal/closest to the ones in the book. \n",
    "# I do not know the details on the differences between the solvers.\n",
    "clf = skl_lm.LogisticRegression(solver='newton-cg')\n",
    "X_train = df.balance.values.reshape(-1,1)\n",
    "clf.fit(X_train,y)\n",
    "print(clf)\n",
    "print('classes: ',clf.classes_)\n",
    "print('coefficients: ',clf.coef_)\n",
    "print('intercept :', clf.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(df.balance)\n",
    "est = smf.Logit(y.ravel(), X_train).fit()\n",
    "est.summary2().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Table 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(df.student2)\n",
    "y = df.default2\n",
    "\n",
    "est = smf.Logit(y, X_train).fit()\n",
    "est.summary2().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Table 4.3 - Multiple Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(df[['balance', 'income', 'student2']])\n",
    "est = smf.Logit(y, X_train).fit()\n",
    "est.summary2().tables[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 4.3 - Confounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# balance and default vectors for students\n",
    "X_train = df[df.student == 'Yes'].balance.values.reshape(df[df.student == 'Yes'].balance.size,1) \n",
    "y = df[df.student == 'Yes'].default2\n",
    "\n",
    "# balance and default vectors for non-students\n",
    "X_train2 = df[df.student == 'No'].balance.values.reshape(df[df.student == 'No'].balance.size,1) \n",
    "y2 = df[df.student == 'No'].default2\n",
    "\n",
    "# Vector with balance values for plotting\n",
    "X_test = np.arange(df.balance.min(), df.balance.max()).reshape(-1,1)\n",
    "\n",
    "clf = skl_lm.LogisticRegression(solver='newton-cg')\n",
    "clf2 = skl_lm.LogisticRegression(solver='newton-cg')\n",
    "\n",
    "clf.fit(X_train,y)\n",
    "clf2.fit(X_train2,y2)\n",
    "\n",
    "prob = clf.predict_proba(X_test)\n",
    "prob2 = clf2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['student','default']).size().unstack('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating plot\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(12,5))\n",
    "\n",
    "# Left plot\n",
    "ax1.plot(X_test, pd.DataFrame(prob)[1], color='orange', label='Student')\n",
    "ax1.plot(X_test, pd.DataFrame(prob2)[1], color='lightblue', label='Non-student')\n",
    "ax1.hlines(127/2817, colors='orange', label='Overall Student',\n",
    "           xmin=ax1.xaxis.get_data_interval()[0],\n",
    "           xmax=ax1.xaxis.get_data_interval()[1], linestyles='dashed')\n",
    "ax1.hlines(206/6850, colors='lightblue', label='Overall Non-Student',\n",
    "           xmin=ax1.xaxis.get_data_interval()[0],\n",
    "           xmax=ax1.xaxis.get_data_interval()[1], linestyles='dashed')\n",
    "ax1.set_ylabel('Default Rate')\n",
    "ax1.set_xlabel('Credit Card Balance')\n",
    "ax1.set_yticks([0, 0.2, 0.4, 0.6, 0.8, 1.])\n",
    "ax1.set_xlim(450,2500)\n",
    "ax1.legend(loc=2)\n",
    "\n",
    "# Right plot\n",
    "sns.boxplot('student', 'balance', data=df, orient='v', ax=ax2,  palette=c_palette);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Linear Discriminant Analysis\n",
    "### Table 4.4 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['balance', 'income', 'student2']].as_matrix()\n",
    "y = df.default2.as_matrix()\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(solver='svd')\n",
    "y_pred = lda.fit(X, y).predict(X)\n",
    "\n",
    "df_ = pd.DataFrame({'True default status': y,\n",
    "                    'Predicted default status': y_pred})\n",
    "df_.replace(to_replace={0:'No', 1:'Yes'}, inplace=True)\n",
    "\n",
    "df_.groupby(['Predicted default status','True default status']).size().unstack('True default status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y, y_pred, target_names=['No', 'Yes']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table 4.5\n",
    "Instead of using the probability of 50% as decision boundary, we say that a probability of default of 20% is to be classified as 'Yes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_prob = 0.2\n",
    "y_prob = lda.fit(X, y).predict_proba(X)\n",
    "\n",
    "df_ = pd.DataFrame({'True default status': y,\n",
    "                    'Predicted default status': y_prob[:,1] > decision_prob})\n",
    "df_.replace(to_replace={0:'No', 1:'Yes', 'True':'Yes', 'False':'No'}, inplace=True)\n",
    "\n",
    "df_.groupby(['Predicted default status','True default status']).size().unstack('True default status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.3 Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/Smarket.csv', usecols=range(1,10), index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[:'2004'][['Lag1','Lag2']]\n",
    "y_train = df[:'2004']['Direction']\n",
    "\n",
    "X_test = df['2005':][['Lag1','Lag2']]\n",
    "y_test = df['2005':]['Direction']\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "pred = lda.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.priors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These do not seem to correspond to the values from the R output in the book?\n",
    "lda.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, pred).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_p = lda.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred_p[:,1]>0.5, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(pred_p[:,1]>0.9, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.4 Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QuadraticDiscriminantAnalysis()\n",
    "pred = qda.fit(X_train, y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda.priors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, pred).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.5 K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = neighbors.KNeighborsClassifier(n_neighbors=3)\n",
    "pred = knn.fit(X_train, y_train).predict(X_test)\n",
    "print(confusion_matrix(y_test, pred).T)\n",
    "print(classification_report(y_test, pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6.6 An Application to Caravan Insurance Data\n",
    "\n",
    "#### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In R, I exported the dataset from package 'ISLR' to a csv file\n",
    "df = pd.read_csv('Data/Caravan.csv')\n",
    "y = df.Purchase\n",
    "X = df.drop('Purchase', axis=1).astype('float64')\n",
    "X_scaled = preprocessing.scale(X)\n",
    "\n",
    "X_train = X_scaled[1000:,:]\n",
    "y_train = y[1000:]\n",
    "X_test = X_scaled[:1000,:]\n",
    "y_test = y[:1000]\n",
    "\n",
    "def KNN(n_neighbors=1, weights='uniform'):\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights)\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    score = clf.score(X_test, y_test)\n",
    "    return(pred, score, clf.classes_)\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, n_neighbors, title='Confusion matrix (Normalized)',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Normalized confusion matrix: KNN-{}'.format(n_neighbors))\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(2), classes)\n",
    "    plt.yticks(np.arange(2), classes)\n",
    "    plt.tight_layout()\n",
    "    plt.xlabel('True label',rotation='horizontal', ha='right')\n",
    "    plt.ylabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1,3,5]:\n",
    "    pred, score, classes = KNN(i)\n",
    "    cm = confusion_matrix(y_test, pred)\n",
    "    cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    plot_confusion_matrix(cm_normalized.T, classes, n_neighbors=i)\n",
    "    cm_df = pd.DataFrame(cm.T, index=classes, columns=classes)\n",
    "    cm_df.index.name = 'Predicted'\n",
    "    cm_df.columns.name = 'True'\n",
    "    print(cm_df)    \n",
    "    print(pd.DataFrame(precision_score(y_test, pred, average=None),\n",
    "                       index=classes, columns=['Precision']))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = skl_lm.LogisticRegression()\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = regr.predict(X_test)\n",
    "cm_df = pd.DataFrame(confusion_matrix(y_test, pred).T, index=regr.classes_,\n",
    "                     columns=regr.classes_)\n",
    "cm_df.index.name = 'Predicted'\n",
    "cm_df.columns.name = 'True'\n",
    "print(cm_df)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_p = regr.predict_proba(X_test)\n",
    "cm_df = pd.DataFrame({'True': y_test, 'Pred': pred_p[:,1] > .25})\n",
    "cm_df.Pred.replace(to_replace={True:'Yes', False:'No'}, inplace=True)\n",
    "print(cm_df.groupby(['True', 'Pred']).size().unstack('True').T)\n",
    "print(classification_report(y_test, cm_df.Pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
